import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import gc
import xgboost as xgb
import lightgbm as lgb
import multiprocessing
cores = multiprocessing.cpu_count()

from tqdm import tqdm
tqdm.pandas()

from imblearn.over_sampling import SMOTE
from numpy.random import RandomState
from collections import Counter

from matplotlib import pyplot

from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, roc_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, MinMaxScaler
from sklearn.impute import SimpleImputer

random_seed = 63445



# Class for data visualization of the training data. 
class data_visualization():
    
    def __init__(self, trainFile):
        self.trainData = pd.read_csv(trainFile)



#   This is the function for getting graphs of some features in the given data.
    def graph_drawing(self):
        self.trainData['HasDetections'].value_counts()
        sns.countplot(x = 'HasDetections', data = self.trainData) 
        sns.countplot(x = 'Census_IsTouchEnabled', hue = 'HasDetections', data = self.trainData)
        plt.show()
        sns.countplot(x = 'Census_ProcessorClass', hue = 'HasDetections', data = self.trainData)
        plt.show()
        sns.countplot(x = 'Platform', hue = 'HasDetections', data = self.trainData)
        plt.show()
        sns.countplot(x = 'Census_ProcessorManufacturerIdentifier', hue = 'HasDetections', data = self.trainData)
        plt.show()
        sns.countplot(x = 'Census_IsPenCapable', hue = 'HasDetections', data = self.trainData)
        plt.show()
        sns.countplot(x = 'Census_DeviceFamily', hue = 'HasDetections', data = self.trainData)
        plt.show()
        sns.countplot(x = 'SMode', hue = 'HasDetections', data = self.trainData)
        plt.show()
        plt.figure(figsize = (20, 8))
        sns.countplot(x = 'Census_TotalPhysicalRAM', hue = 'HasDetections', data = self.trainData)
        plt.show()
        fig, ax = plt.subplots(figsize = (15, 8))
        sns.countplot(x = 'Census_PowerPlatformRoleName', hue = 'HasDetections', data = self.trainData)
        ax.set(yscale = 'log')
        plt.show()
        fig, ax = plt.subplots(figsize = (15, 8))
        sns.countplot(x = 'Census_FlightRing', hue = 'HasDetections', data = self.trainData)
        ax.set(yscale = 'log')
        plt.show()
        


# Class for preprocessing and model training on the given training data.
class model():
    
    def __init__(self, trainFile, testFile):
        self.trainFile = trainFile
        self.testFile = testFile
        self.trainData = None
        self.testData = None
        self.identifier = None
        self.y = None
        self.all_cols = None
        self.train_x = None
        self.predict_x = None
        self.total = None
        self.train = None
        self.test_x = None
        self.train_y = None
        self.test_y = None
        self.final_y = None
        self.xgb_classifier = xgb.XGBClassifier(learning_rate = 0.05, n_estimators = 3000, max_depth = 9, min_child_weight = 7, gamma = 0.2, subsample = 1, 
                                                colsample_bytree = 1, objective = 'binary:logistic', nthread = -1, scale_pos_weight = 1, reg_alpha = 0.6, 
                                                reg_lambda = 3, seed = 42, n_jobs = cores)
        self.lgb_classifier = lgb.LGBMClassifier(n_estimators = 900, n_jobs = cores, objective = 'binary', random_state = 50, max_depth = 10, min_data_in_leaf = 22,
                                                 eta = 0.05, lambda_l2 = 0.3, lambda_l1 = 0.0, num_leaves = 31)
        

        
#   Function for reading training and testing data.
    def read_data(self):
        self.trainData = pd.read_csv(self.trainFile)
        self.testData  = pd.read_csv(self.testFile)
        self.identifier = self.testData['MachineIdentifier']
        self.y = self.trainData.HasDetections
        self.trainData.drop(['HasDetections'], axis = 1, inplace = True)
    
    
    
#   Function for dropping some columns from the training and testing data.
    def remove_columns(self):
        primary_analysis = []
        for col in self.trainData.columns:
            primary_analysis.append((col, len(pd.unique(self.trainData[col])), self.trainData[col].dtype, (self.trainData[col].isnull().sum())/self.trainData[col].shape[0], 
                                     (self.trainData[col].value_counts(dropna = False).values[0])/self.trainData[col].shape[0]))
    
        col_to_remove = []
        
#       There are some columns which have 90% of data in one category. There are some columns which have 99% NULL values. So I think these columns are of no use.        
        for col in self.trainData.columns:
            a = (self.trainData[col].value_counts(dropna = False).values[0])/self.trainData[col].shape[0]
            b = (self.trainData[col].isnull().sum())/self.trainData[col].shape[0]
            c = len(self.trainData[col].value_counts(dropna = False))
            if a > 0.9 or b > 0.99 or c < 2 or col == 'MachineIdentifier':
                col_to_remove.append(col)
        more_cols = ['Census_IsTouchEnabled', 'HasTpm', 'Census_IsVirtualDevice', 'SMode', 'Census_IsPenCapable', 'Platform', 'Census_ProcessorManufacturerIdentifier',
                     'Census_IsAlwaysOnAlwaysConnectedCapable', 'Census_IsPortableOperatingSystem', 'OsVer', 'Census_DeviceFamily']
        col_to_remove = col_to_remove + more_cols
        self.all_cols = [col for col in self.trainData.columns if col not in col_to_remove]
        self.trainData = self.trainData[self.all_cols]
        self.testData = self.testData[self.all_cols]
    
    
    
#   This function helps in imputing NULL values in the dataset. All categorical features have been replaced with most frequent values and continous features have been 
#   replaced with mean.
    def impute(self, curr):
        for col in self.all_cols:
            if curr[col].dtype == 'object' or len(curr[col].unique()) <= 10:
                si = SimpleImputer(strategy = 'most_frequent')
                curr[col] = si.fit_transform(curr[[col]])
            else:
                si = SimpleImputer(strategy = 'mean')
                curr[col] = si.fit_transform(curr[[col]])
                
    
    
#   The below function performs some data cleaning and ordinal encoding of some features which we thought were necessary.    
    def ordinal(self):
        engine_version = list(self.total.EngineVersion.value_counts().index)
        engine_version.sort()
        oe = OrdinalEncoder(categories = [engine_version])
        self.total['EngineVersion'] = oe.fit_transform(self.total[['EngineVersion']])

        app_version = list(self.total.AppVersion.value_counts().index)
        app_version.sort()
        oe = OrdinalEncoder(categories = [app_version])
        self.total['AppVersion'] = oe.fit_transform(self.total[['AppVersion']])

        avg_sig_version = list(self.total.AvSigVersion.value_counts().index)
        avg_sig_version.sort()
        oe = OrdinalEncoder(categories = [avg_sig_version])
        self.total['AvSigVersion'] = oe.fit_transform(self.total[['AvSigVersion']])


        oe = OrdinalEncoder(categories = [['arm64','x86','x64']])
        oe.fit(self.total[['Processor']])
        self.total['Processor'] = oe.transform(self.total[['Processor']])
        oe = OrdinalEncoder(categories = [['windows7','windows8.1','th1','th2','rs1','rs2','rs3','rs4','prers5']])
        oe.fit(self.total[['OsPlatformSubRelease']])
        self.total['OsPlatformSubRelease'] = oe.transform(self.total[['OsPlatformSubRelease']])

        self.total.SmartScreen.replace('on', 'On', inplace = True)
        self.total.SmartScreen.replace('Enabled', 'On', inplace = True)
        self.total.SmartScreen.replace('requireadmin', 'RequireAdmin', inplace = True)
        self.total.SmartScreen.replace('prompt', 'Prompt', inplace = True)

        self.total.Census_PrimaryDiskTypeName.replace('Unspecified', 'UNKNOWN', inplace = True)

        self.total.Census_ChassisTypeName.replace('30', 'Notebook', inplace = True)
        self.total.Census_ChassisTypeName.replace('0', 'Notebook', inplace = True)
        self.total.Census_ChassisTypeName.replace('35', 'Notebook', inplace = True)
        self.total.Census_ChassisTypeName.replace('127', 'Notebook', inplace = True)
        self.total.Census_ChassisTypeName.replace('31', 'Notebook', inplace = True)
        self.total.Census_ChassisTypeName.replace('49', 'Notebook', inplace = True)
        self.total.Census_InternalBatteryType.replace('2337', 'lion', inplace = True)

        os_version = list(self.total.Census_OSVersion.value_counts().index)
        os_version.sort()
        oe = OrdinalEncoder(categories = [os_version])
        self.total['Census_OSVersion'] = oe.fit_transform(self.total[['Census_OSVersion']])
        
     
    
#   This is the function for label encoding of data which was not ordinal encoded.    
    def label_encoded(self):
        le = LabelEncoder()
        for col in self.total.columns:
            if self.total[col].dtype == 'object':
                self.total[col] = le.fit_transform(self.total[col])
    
    
    
#   Fucntion is used for splitting 10% of the given training data for testing and the distribution of classes in training and testing data is the same.      
    def split(self):
        self.train, self.test_x, self.train_y, self.test_y = train_test_split(self.train_x, self.y, test_size = 0.1, shuffle = True, random_state = 2020, stratify = self.y)
    
    
    
#   Fucntion for training our xgb classifier using training data. 
    def xgb_fit(self):
        self.xgb_classifier.fit(self.train, self.train_y, eval_set = [(self.test_x, self.test_y)], early_stopping_rounds = 100, eval_metric = 'auc', verbose = 100)
    
    
    
#   Fucntion to calculate prediction. Output matrix.
    def predictions(self, text, x):
        print()
        print(text)
        if x == 1 or x == 0:
            if x == 1:
                predicts = self.xgb_classifier.predict(self.train)
            else:
                predicts = self.lgb_classifier.predict(self.train)
            print()
            print("accuracy_score: ", accuracy_score(self.train_y, predicts))
        predict_probas = (1-x)*self.lgb_classifier.predict_proba(self.test_x) + (x)*self.xgb_classifier.predict_proba(self.test_x)
        print()
        print("roc-auc score from target 'HasDetections': ", roc_auc_score(self.test_y, predict_probas[ : , 1]))
        pyplot.figure(figsize = (7, 7))
        lr_fpr, lr_tpr, _ = roc_curve(test_y, predict_probas[ : , 1])
        pyplot.plot(lr_fpr, lr_tpr, marker = '.', label = 'Logistic')
        pyplot.xlabel('False Positive Rate')
        pyplot.ylabel('True Positive Rate')
        pyplot.legend()
        pyplot.show()
        print()
        gc.collect()

        
        
#   This function is for training our lgb classifier using training data.
    def lgb_fit(self):
        self.lgb_classifier.fit(self.train, self.train_y)
    
    
  
#   Function for getting submission file after running our model on given testing data.
    def fin_submission(self, x):
        self.final_y = (1-x)*self.lgb_classifier.predict_proba(self.predict_x) + (x)*self.xgb_classifier.predict_proba(self.predict_x)
        self.final_y = (self.final_y).astype(np.float64)[:,1]
        self.final_y = pd.DataFrame(self.final_y)
        self.final_y['HasDetections'] = self.final_y[0]
        self.final_y.drop([0], axis = 1, inplace = True)
        self.final_y['MachineIdentifier'] = self.identifier
        self.final_y.drop([0])
        self.final_y.to_csv('submission.csv', index = False)
        
        
        
#   The below is a helper function which preprocesses all the data together train and test and then finally returns the updated dataset.        
    def to_call(self):
        self.read_data()
        self.remove_columns()
        
        self.impute(self.trainData)
        self.impute(self.testData)
        
        self.trainData['train'] = 1
        self.testData['train'] = 0
        self.total = pd.concat([self.trainData, self.testData])
        
        self.ordinal()
        self.label_encoded()
        
        self.train_x = self.total[self.total['train'] == 1]
        self.predict_x = self.total[self.total['train'] == 0]
        self.trainData.drop(['train'], axis = 1, inplace = True)
        self.testData.drop(['train'], axis = 1, inplace = True)
        
        self.split()
        
        self.xgb_fit()
        self.lgb_fit()
        
        self.predictions("In xgb_classifier performance: ", 1)
        self.predictions("In lgb_classifier performance: ", 0)
        self.predictions("In ensemble classifier of xgb_classifier and lbg_classfier", 0.55001)
        
        self.fin_submission(0.55001)
        
        
             
if __name__ == "__main__":
    
    train_data_name = "../input/Malware-detection-NS/train.csv"
    test_data_name  = "../input/Malware-detection-NS/test.csv"

    visual = data_visualization(train_data_name)
    visual.graph_drawing()
    
    trained_model = model(train_data_name, test_data_name)
    trained_model.to_call()

